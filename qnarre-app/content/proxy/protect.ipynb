{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn, Adapt And Protect From \"Elite\" Predators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO: expand bullets\n",
    "\n",
    "- Deceive, Deceive: The more \"elite\", the more deceitful\n",
    "- Low-Cost communication: professional profiling becomes \"two way\"\n",
    "- The era of evolutionary competition of mighty AIs\n",
    "\n",
    "- more detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we have already too much accumulated code to load into our notebook. For your refence, we sample from the attached local source files: *datasets.py, layers.py, main.py, modules.py, samples.py, tasks.py, trafo.py* and *utils.py*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ks = tf.keras\n",
    "\n",
    "def train_eager(ps, ds, m):\n",
    "    def step(x, t):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y = m(x)\n",
    "            loss = ps.loss(t, y)\n",
    "            loss += sum(m.losses)\n",
    "            xent = ps.metric(t, y)\n",
    "        grads = tape.gradient(loss, m.trainable_variables)\n",
    "        ps.optimizer.apply_gradients(zip(grads, m.trainable_variables))\n",
    "        return loss, xent\n",
    "\n",
    "    @tf.function\n",
    "    def epoch():\n",
    "        s, loss, xent = 0, 0.0, 0.0\n",
    "        for x, y in ds:\n",
    "            s += 1\n",
    "            loss, xent = step(x, y)\n",
    "            if tf.equal(s % 10, 0):\n",
    "                e = ps.metric.result()\n",
    "                tf.print('Step:', s, ', loss:', loss, ', xent:', e)\n",
    "        return loss, xent\n",
    "\n",
    "    for e in range(ps.num_epochs):\n",
    "        loss, xent = epoch()\n",
    "        print(f'Epoch {e} loss:', loss.numpy(), ', xent:', xent.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ps, ds, m):\n",
    "    mp = pth.Path('/tmp/q/model')\n",
    "    if tf.train.get_checkpoint_state(str(mp)):\n",
    "        m.train_on_batch(ds)\n",
    "        m.load_weights(str(mp / f'{m.name}'))\n",
    "        loss, xent = m.evaluate(ds)\n",
    "        print(f'\\nEvaluate loss, xent: {loss}, {xent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ps, ds, m):\n",
    "    mp = pth.Path('/tmp/q/model')\n",
    "    if tf.train.get_checkpoint_state(str(mp)):\n",
    "        m.train_on_batch(ds)\n",
    "        m.load_weights(str(mp / f'{m.name}'))\n",
    "        for x, t in ds:\n",
    "            y = m.predict(x)\n",
    "            print(y, t.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our final blog in this section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.qpy)",
   "language": "python",
   "name": "qpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
