{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Callbacks: Extending Their Scope And Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a transitioning piece between our to groups of blogs, this blog is still work in progress.\n",
    "\n",
    "It concerns the various `callbacks` that we can register during training sessions.\n",
    "\n",
    "As automating our sessions is an important objective of ours, specifically to enable us to fine-tune our training `hyper-parameters`, we will be adding to this blog as the rest of the next group's blogs materialize.\n",
    "\n",
    "Just as before, we need to prep our environment to run any meaningful code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pathlib as pth\n",
    "import tensorflow as tf\n",
    "import dataset as qd\n",
    "import custom as qc\n",
    "ks = tf.keras\n",
    "kl = ks.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are ready to define our model.\n",
    "\n",
    "As this blog focuses on the actual training process, our model can be reused directly from a previous blog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for(ps):\n",
    "    x = [ks.Input(shape=(), dtype='int32'), ks.Input(shape=(), dtype='int64')]\n",
    "    x += [ks.Input(shape=(), dtype='int32'), ks.Input(shape=(), dtype='int64')]\n",
    "    x += [ks.Input(shape=(), dtype='int32'), ks.Input(shape=(), dtype='int64')]\n",
    "    y = qc.ToRagged()(x)\n",
    "    y = qc.Frames(ps)(y)\n",
    "    embed = qc.Embed(ps)\n",
    "    ye = qc.Encode(ps)(embed(y[:2]))\n",
    "    yd = qc.Decode(ps)(embed(y[2:]) + [ye[0]])\n",
    "    y = qc.Debed(ps)(yd)\n",
    "    m = ks.Model(name='callbacks', inputs=x, outputs=y)\n",
    "    m.compile(optimizer=ps.optimizer, loss=ps.loss, metrics=[ps.metric])\n",
    "    print(m.summary())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is defined, we adjust our main calling function.\n",
    "\n",
    "At this point we define our `callbacks` that should be kept \"in loop\" during our training session.\n",
    "\n",
    "Initially we still want to include the standard Keras TensorBoard callbacks.\n",
    "\n",
    "Additionally, we want to roll our own checkpointing. We choose to use the latest `Checkpoint` and `CheckpointManager` classes (see our [blog](./trackable.html) regarding this topic).\n",
    "\n",
    "For this we define a custom Keras `Callback` class called `CheckpointCB`. As this callback is only used to save or update our current checkpoint file, it only needs to override the `on_epoch_end` callback.\n",
    "\n",
    "In the override it simply calls the manager's `save` method.  \n",
    "\n",
    "To be expanded..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_graph(ps, ds, m):\n",
    "    b = pth.Path('/tmp/q')\n",
    "    b.mkdir(parents=True, exist_ok=True)\n",
    "    lp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    lp = b / f'logs/{lp}'\n",
    "    c = tf.train.Checkpoint(model=m)\n",
    "    mp = b / 'model' / f'{m.name}'\n",
    "    mgr = tf.train.CheckpointManager(c, str(mp), max_to_keep=3)\n",
    "    # if mgr.latest_checkpoint:\n",
    "    #     vs = tf.train.list_variables(mgr.latest_checkpoint)\n",
    "    #     print(f'\\n*** checkpoint vars: {vs}')\n",
    "    c.restore(mgr.latest_checkpoint).expect_partial()\n",
    "\n",
    "    class CheckpointCB(ks.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            mgr.save()\n",
    "\n",
    "    cbs = [\n",
    "        CheckpointCB(),\n",
    "        ks.callbacks.TensorBoard(\n",
    "            log_dir=str(lp),\n",
    "            histogram_freq=1,\n",
    "        ),\n",
    "    ]\n",
    "    m.fit(ds, callbacks=cbs, epochs=ps.num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also need to update our parameters as they relate to our \"callback objectives\".\n",
    "\n",
    "To be expanded..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    dim_batch=5,\n",
    "    dim_dense=150,\n",
    "    dim_hidden=6,\n",
    "    dim_stacks=2,\n",
    "    dim_vocab=len(qd.vocab),\n",
    "    loss=ks.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metric=ks.metrics.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    num_epochs=5,\n",
    "    num_shards=2,\n",
    "    optimizer=ks.optimizers.Adam(),\n",
    "    width_dec=15,\n",
    "    width_enc=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are ready to start our training session.\n",
    "\n",
    "We can confirm the model's layers and connections. We can easily adjust the parameters to tailor the length of the sessions to our objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"callbacks\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "to_ragged (ToRagged)            [(None, None), (None 0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "frames (Frames)                 [(5, 25), (None,), ( 125         to_ragged[0][0]                  \n",
      "                                                                 to_ragged[0][1]                  \n",
      "                                                                 to_ragged[0][2]                  \n",
      "__________________________________________________________________________________________________\n",
      "embed (Embed)                   multiple             120         frames[0][0]                     \n",
      "                                                                 frames[0][1]                     \n",
      "                                                                 frames[0][2]                     \n",
      "                                                                 frames[0][3]                     \n",
      "__________________________________________________________________________________________________\n",
      "encode (Encode)                 [(None, 25, 6), (Non 90516       embed[0][0]                      \n",
      "                                                                 embed[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "decode (Decode)                 [(None, 15, 6), (Non 54732       embed[1][0]                      \n",
      "                                                                 embed[1][1]                      \n",
      "                                                                 encode[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "debed (Debed)                   (None, None, None)   140         decode[0][0]                     \n",
      "                                                                 decode[0][1]                     \n",
      "==================================================================================================\n",
      "Total params: 145,633\n",
      "Trainable params: 145,508\n",
      "Non-trainable params: 125\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 15s 733ms/step - loss: 1.3225 - sparse_categorical_crossentropy: 1.3311\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2037 - sparse_categorical_crossentropy: 1.2163\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2067 - sparse_categorical_crossentropy: 1.2187\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.1113 - sparse_categorical_crossentropy: 1.1200\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0234 - sparse_categorical_crossentropy: 1.0336\n"
     ]
    }
   ],
   "source": [
    "ps = qd.Params(**params)\n",
    "main_graph(ps, qc.dset_for(ps), model_for(ps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick `ls` into our `/tmp/q/model/callbacks` checkpoint directory shows that our manager is in fact updating the checkpoint files and it is keeping only the last three, just as we expect.\n",
    "\n",
    "To be expanded..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
