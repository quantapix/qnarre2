{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified Adaptable Masking That Follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant difference between image vs. text processing in machine learning is even vs. uneven input sequence length. Padding uneven textual input to a uniform length is an obvious, natural solution.\n",
    "\n",
    "Indiscriminate padding can, however, pollute our calculations and introduce unwanted biases. Sometimes it is best to cleanly “mask-out” the padded input with carefully chosen, bias minimizing values.\n",
    "\n",
    "Repeated, explicit and contextual masking calculations become necessary as a result. Historically such code has been cluttering the otherwise clean \"flow of data\". Keras’ transparent masking mechanism allows for on-demand custom maskings.\n",
    "\n",
    "Our objective here is to arrive at a model representable by the [graph](./masking.pdf).\n",
    "\n",
    "Just as before, we need to prep our environment to run any meaningful code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import dataset as qd\n",
    "ks = tf.keras\n",
    "kl = ks.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our already created meta data from the sources gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ', ':', '|', 'x', 'y', '=', ',', '+', '-', '*', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
      "{' ': 0, ':': 1, '|': 2, 'x': 3, 'y': 4, '=': 5, ',': 6, '+': 7, '-': 8, '*': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19}\n"
     ]
    }
   ],
   "source": [
    "print(qd.vocab)\n",
    "print(qd.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To \"adapt\" our existing datasets, we recast our parsed streams and start using the new `RaggedTensor`s instead of the default sparse ones.\n",
    "\n",
    "We also combine existing `feature`s into new ones by inserting separator tokens between the concatenated pieces.\n",
    " \n",
    "Before handing the prepared streams of data to Keras, we still need to convert them to dense tensors. Most importantly, we pad the tensors to `len_max_input`, with generic zeros, for uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def caster(d):\n",
    "    return {k: tf.cast(v, tf.int32) for k, v in d.items()}\n",
    "\n",
    "SEP = qd.tokens[':']\n",
    "print(qd.SEP)\n",
    "\n",
    "@tf.function\n",
    "def adapter(d, len_max_input):\n",
    "    ds = tf.RaggedTensor.from_sparse(d['defs'])\n",
    "    ss = tf.fill([ds.nrows(), 1], qd.SEP)\n",
    "    os = tf.RaggedTensor.from_sparse(d['op'])\n",
    "    x = tf.concat([ds, ss, os], axis=1).to_tensor()\n",
    "    x = tf.pad(x, [[0, 0], [0, len_max_input - tf.shape(x)[-1]]])\n",
    "    y = tf.RaggedTensor.from_sparse(d['res'])[:, :1].to_tensor()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A newly created function will return the paths to our existing file shards.\n",
    "\n",
    "And now we are ready to create our datasets, custom-adapted to our problem at hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files(ps):\n",
    "    d = pth.Path('/tmp/q/dataset')\n",
    "    for i in range(ps.num_shards):\n",
    "        i = '{:0>4d}'.format(i)\n",
    "        yield str(d / f'shard_{i}.tfrecords')\n",
    "\n",
    "def dset_for(ps):\n",
    "    ds = tf.data.TFRecordDataset(list(qd.files(ps)))\n",
    "    ds = ds.batch(ps.dim_batch)\n",
    "    fs = {\n",
    "        'defs': tf.io.VarLenFeature(tf.int64),\n",
    "        'op': tf.io.VarLenFeature(tf.int64),\n",
    "        'res': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    ds = ds.map(lambda x: tf.io.parse_example(x, fs)).map(qd.caster)\n",
    "    return ds.map(lambda d: adapter(d, tf.constant(ps.len_max_input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to tell our custom Keras layers to support masking. Let's do it once for all of them in our own `Layer` base class. We simply inherit from it for all other layers.\n",
    "\n",
    "Our first layer, the one receiving the to-be-masked input and needing to specifically calculate the versatile `bool` masking tensor, has to override the `compute_mask` method.\n",
    "\n",
    "We could also transfer the mask calculation to another layer that would do it as an efficient side-effect of its own tasks. In that case we would use the 2 commented out lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(kl.Layer):\n",
    "    def __init__(self, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.supports_masking = True\n",
    "\n",
    "class Masking(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self._compute_output_and_mask_jointly = True\n",
    "\n",
    "    def compute_mask(self, x, mask=None):\n",
    "        return tf.not_equal(x, 0)\n",
    "\n",
    "    def call(self, x):\n",
    "        # x._keras_mask = self.compute_mask(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to turn our impossibly \"tight\" `int32` tokens into something more useful for machine learning, we need to `Embed` them into a much higher dimensional \"space\".\n",
    "\n",
    "Our embedding layer, however, is as simple as it gets: it first creates the embedding table and then does the actual lookup using the input tokens.\n",
    "\n",
    "Once the embedded values are determined, we apply our straightforward `bool` masking cleanly, always resetting the masked-out, high dimensional values to `0` regardless of any \"learned\" adjustments.\n",
    "\n",
    "During layer processing, Keras knows that we want to use the transparently hidden mask tensor from our included `mask=None` keyword argument in the `call` method's signature.\n",
    "\n",
    "For `autograph`'s sake we need to also explicitly check that the optional `mask` argument is `not None`; a simple intuitive `if mask:` would only trigger \"trace execution\" instead of \"graph execution\" in our later blogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embed(Layer):\n",
    "    def __init__(self, ps):\n",
    "        super().__init__(dtype=tf.float32)\n",
    "        s = (ps.dim_vocab, ps.dim_hidden)\n",
    "        self.emb = self.add_weight(name='emb', shape=s)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        y = tf.nn.embedding_lookup(self.emb, x)\n",
    "        if mask is not None:\n",
    "            y *= tf.cast(mask, tf.float32)[:, :, None]\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our self-attention layer, fittingly called `Reflect`, does the absolute minimum required steps to implement the \"attention\" mechanism of the `transformer` architecture. An excellent, creative explanation of how it works is at http://jalammar.github.io/illustrated-transformer/.\n",
    "\n",
    "The masking tensor is being automatically supplied to the call by Keras. Once again, we only need to state our intention to mask by adding the `mask=None` keyword argument.\n",
    "\n",
    "The actual masking calculation, based on our previously created `bool` tensor and specific for this layer only, is outright trivial. It simply replaces the to-be-masked values with large negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reflect(Layer):\n",
    "    def build(self, shape):\n",
    "        s = shape[-1]\n",
    "        self.scale = 1 / (s**0.5)\n",
    "        self.q = self.add_weight(name='q', shape=(s, s))\n",
    "        self.k = self.add_weight(name='k', shape=(s, s))\n",
    "        self.v = self.add_weight(name='v', shape=(s, s))\n",
    "        return super().build(shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        q = tf.einsum('bsi,ij->bsj', x, self.q)\n",
    "        k = tf.einsum('bsi,ij->bsj', x, self.k)\n",
    "        y = tf.einsum('bsi,bzi->bsz', q, k) * self.scale\n",
    "        if mask is not None:\n",
    "            # tf.print(' *** applying mask')\n",
    "            m = tf.logical_not(mask)\n",
    "            m = tf.cast(m, tf.float32)[:, :, None]\n",
    "            y += m * -1e9\n",
    "        v = tf.einsum('bsi,ij->bsj', x, self.v)\n",
    "        y = tf.einsum('bsz,bzi->bsi', tf.nn.softmax(y), v)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to create and compile our Keras `functional` model.\n",
    "\n",
    "As the objective of this blog is to showcase masking, all the other necessary \"plumbing\" layers are the canned Keras variety ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for(ps):\n",
    "    x = ks.Input(shape=(ps.len_max_input, ), dtype='int32')\n",
    "    y = Masking()(x)\n",
    "    y = Embed(ps)(y)\n",
    "    y = Reflect()(y)\n",
    "    y = kl.Reshape((ps.len_max_input * ps.dim_hidden, ))(y)\n",
    "    y = kl.Dense(ps.dim_dense, activation='relu')(y)\n",
    "    y = kl.Dense(ps.dim_vocab, name='dbd', activation=None)(y)\n",
    "    m = ks.Model(inputs=x, outputs=y)\n",
    "    m.compile(optimizer=ps.optimizer, loss=ps.loss, metrics=[ps.metric])\n",
    "    print(m.summary())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count of our parameters have slightly increased, otherwise they are the same as before. Please see the previous blog for the justification of the `Params` class and the overall scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    dim_batch=2,\n",
    "    dim_dense=150,\n",
    "    dim_hidden=15,\n",
    "    dim_vocab=len(qd.vocab),\n",
    "    len_max_input=20,\n",
    "    loss=ks.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metric=ks.metrics.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    num_epochs=10,\n",
    "    num_shards=2,\n",
    "    optimizer=ks.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "class Params:\n",
    "    def __init__(self, **kw):\n",
    "        for k, v in kw.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we instantiate our parameters and our dataset, and using the already compiled model, we are ready to start a training session conveniently implemented by the Keras `fit` method.\n",
    "\n",
    "Our aim is to use as much of the versatility, functionality and error checking that Keras provides, so using the model's `fit` method is all we need for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embed (Embed)                (None, 20, 15)            300       \n",
      "_________________________________________________________________\n",
      "reflect (Reflect)            (None, 20, 15)            675       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dbd (Dense)                  (None, 20)                3020      \n",
      "=================================================================\n",
      "Total params: 49,145\n",
      "Trainable params: 49,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7373 - sparse_categorical_crossentropy: 1.7373\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4499 - sparse_categorical_crossentropy: 1.4499\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3553 - sparse_categorical_crossentropy: 1.3553\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2888 - sparse_categorical_crossentropy: 1.2888\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2299 - sparse_categorical_crossentropy: 1.2299\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1706 - sparse_categorical_crossentropy: 1.1706\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1019 - sparse_categorical_crossentropy: 1.1019\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0223 - sparse_categorical_crossentropy: 1.0223\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9478 - sparse_categorical_crossentropy: 0.9478\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8824 - sparse_categorical_crossentropy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "def main_graph(ps, ds, m):\n",
    "    ld = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    ld = f'/tmp/q/logs/{ld}'\n",
    "    cs = [ks.callbacks.TensorBoard(log_dir=ld, histogram_freq=1)]\n",
    "    m.fit(ds, callbacks=cs, epochs=ps.num_epochs)\n",
    "\n",
    "ps = qd.Params(**params)\n",
    "main_graph(ps, dset_for(ps), model_for(ps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our TensorBoard `callback` in place, the model's `fit` method will generate the standard summaries that TensorBoard can conveniently visualize.\n",
    "\n",
    "If you haven't run the below code, an already generated graph is [here](./masking.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir /tmp/q/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our blog, please see how to use the new `RaggedTensors` instead of masking by clicking on the next blog."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.qpy)",
   "language": "python",
   "name": "qpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
