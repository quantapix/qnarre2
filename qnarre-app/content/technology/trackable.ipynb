{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trackable: A Pervasive Persistence Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training in TensorFlow means continually adjusting collections of values stored as `tensors` in objects called `variables`.\n",
    "\n",
    "The persistence of these variables, from one training session to the next, is critical for improving on the already achieved, but otherwise long-running results.\n",
    "\n",
    "A new system-wide pervasive `trackable` architecture now provides just such a persistence infrastructure. Instead of the old name-based hierarchy, the new design applies a topological, \"layered objects\" naming scheme.\n",
    "\n",
    "In this first blog, we explore some of the key aspects of this architecture. We start with a high-level view and then we gradually build from the simple base classes to the more useful Keras `layers`.\n",
    "\n",
    "Our objective is to arrive at a training model representable by the [graph](./trackable.pdf).\n",
    "\n",
    "We first need to prep our environment to run any meaningful code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorflow.python.training.tracking import base\n",
    "from tensorflow.python.training.tracking import tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual persistence of training data, the `weights`, is ultimately realized through explicit `Checkpoint` objects.\n",
    "\n",
    "As the number of such representations grows, saved as efficiently encoded versioned files, `CheckpointManager`s help with keeping track (see TF docs for full functionality).\n",
    "\n",
    "We present a simple scenario for persisting (saving and restoring) a single-valued variable encapsulated by a `Trackable` object as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trackable(tr1, v):\n",
    "    c = tf.train.Checkpoint(tr1=tr1)\n",
    "    m = tf.train.CheckpointManager(c, '/tmp/q/trackable', max_to_keep=2)\n",
    "    p = m.latest_checkpoint\n",
    "    c.restore(p).expect_partial()\n",
    "    if p:\n",
    "        print(f'restored from: {p}')\n",
    "        print(f'others are: {m.checkpoints}')\n",
    "    else:\n",
    "        print('start from scratch')\n",
    "    print(f'value before: {v.numpy()}')\n",
    "    v.assign_add(1)\n",
    "    m.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above function, our 3 iterations of incrementing the single-valued `int` variable and keeping track of the `Checkpoint` files result in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from scratch\n",
      "value before: 1\n",
      "restored from: /tmp/q/trackable/ckpt-1\n",
      "others are: ['/tmp/q/trackable/ckpt-1']\n",
      "value before: 2\n",
      "restored from: /tmp/q/trackable/ckpt-2\n",
      "others are: ['/tmp/q/trackable/ckpt-1', '/tmp/q/trackable/ckpt-2']\n",
      "value before: 3\n"
     ]
    }
   ],
   "source": [
    "tr1 = base.Trackable()\n",
    "v = tf.Variable(1)\n",
    "tr1._track_trackable(v, name='tr1_v')\n",
    "for _ in range(3):\n",
    "    trackable(tr1, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above snippet is fully functional, the extensive boiler-plate code becomes an unnecessary hassle when implementing even slightly more complex schemes.\n",
    "\n",
    "Also note that we used a private, undocumented and non-API method to make our code work. A more convenient \"auto-tracking\" functionality is needed.\n",
    "\n",
    "The native Python attribute mechanism conveniently provides a framework to satisfy such needs as we'll see in a moment.\n",
    "\n",
    "In preparation, our slightly adjusted printing function is now as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autotrackable(tr2, tracked, untracked):\n",
    "    c = tf.train.Checkpoint(tr2=tr2)\n",
    "    m = tf.train.CheckpointManager(c, '/tmp/q/trackable', max_to_keep=2)\n",
    "    p = m.latest_checkpoint\n",
    "    c.restore(p).expect_partial()\n",
    "    if p:\n",
    "        print(f'restored from: {p}')\n",
    "    print(f'values before: {tracked.numpy()}, {untracked.numpy()}')\n",
    "    tracked.assign_add(1000)\n",
    "    m.save()\n",
    "    print(f'value as saved: {tracked.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is our use of an `AutoTrackable` object holding onto 2 single-valued variables.\n",
    "\n",
    "Notice the intuitive `tr2.v = tracked` assignment, as this is where the entire \"trackable\" scheme is triggered.\n",
    "\n",
    "Just in case we want to avoid the default functionality, we can turn off auto-tracking as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restored from: /tmp/q/trackable/ckpt-3\n",
      "values before: 1000, 0\n",
      "value as saved: 2000\n",
      "restored from: /tmp/q/trackable/ckpt-4\n",
      "values before: 2000, 0\n",
      "value as saved: 3000\n"
     ]
    }
   ],
   "source": [
    "tr2 = tracking.AutoTrackable()\n",
    "tracked, untracked = tf.Variable(1000), tf.Variable(0)\n",
    "tr2.v = tracked\n",
    "with base.no_automatic_dependency_tracking_scope(tr2):\n",
    "    tr2.untracked = untracked\n",
    "for _ in range(2):\n",
    "    autotrackable(tr2, tracked, untracked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employing the native Python attribute mechanism and assignment operator allows us to reliably \"auto track\" hundreds or thousands of training variables.\n",
    "\n",
    "Moreover, a consistent hierarchical \"layered objects\" naming scheme emerges, without the need for explicit, string-based names.\n",
    "\n",
    "For a snapshot view of the \"topology\" of our layers, or just a simple inventory of our variables, we can use the helper functions provided by TF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listing():\n",
    "    c = tf.train.Checkpoint()\n",
    "    m = tf.train.CheckpointManager(c, '/tmp/q/trackable', max_to_keep=2)\n",
    "    p = m.latest_checkpoint\n",
    "    vs = tf.train.list_variables(p)\n",
    "    print(f'names and shapes list: {vs}')\n",
    "    n, _ = vs[-1]\n",
    "    v = tf.train.load_variable(p, n)\n",
    "    print(f'loaded value: {v} for name: {n}')\n",
    "    c = tf.train.load_checkpoint(p)\n",
    "    ts = c.get_variable_to_dtype_map()\n",
    "    ss = c.get_variable_to_shape_map()\n",
    "    print(f'checkpoint types: {ts} and shapes: {ss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the result of calling our function, we can quickly grasp the otherwise simple pattern of hierarchical naming convention employed by the architecture: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names and shapes list: [('_CHECKPOINTABLE_OBJECT_GRAPH', []), ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', []), ('tr2/v/.ATTRIBUTES/VARIABLE_VALUE', [])]\n",
      "loaded value: 3000 for name: tr2/v/.ATTRIBUTES/VARIABLE_VALUE\n",
      "checkpoint types: {'tr2/v/.ATTRIBUTES/VARIABLE_VALUE': tf.int32, '_CHECKPOINTABLE_OBJECT_GRAPH': tf.string, 'save_counter/.ATTRIBUTES/VARIABLE_VALUE': tf.int64} and shapes: {'tr2/v/.ATTRIBUTES/VARIABLE_VALUE': [], '_CHECKPOINTABLE_OBJECT_GRAPH': [], 'save_counter/.ATTRIBUTES/VARIABLE_VALUE': []}\n"
     ]
    }
   ],
   "source": [
    "listing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any type of variable management system that allows creating variables must also support deleting them.\n",
    "\n",
    "The familiar native Python attribute mechanism's `del` operation is used to delete a variable from the hierarchy, just as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleting(tr2):\n",
    "    c = tf.train.Checkpoint(tr2=tr2)\n",
    "    m = tf.train.CheckpointManager(c, '/tmp/q/trackable', max_to_keep=2)\n",
    "    c.restore(m.latest_checkpoint)\n",
    "    c.tr2.deleted = tf.Variable(-1)\n",
    "    m.save()\n",
    "    vs = tf.train.list_variables(m.latest_checkpoint)\n",
    "    print(f'list deleted: {vs}')\n",
    "    del c.tr2.deleted\n",
    "    m.save()\n",
    "    vs = tf.train.list_variables(m.latest_checkpoint)\n",
    "    print(f'deleted IS DELETED: {vs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the results of calling our `deleting` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list deleted: [('_CHECKPOINTABLE_OBJECT_GRAPH', []), ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', []), ('tr2/deleted/.ATTRIBUTES/VARIABLE_VALUE', []), ('tr2/v/.ATTRIBUTES/VARIABLE_VALUE', [])]\n",
      "deleted IS DELETED: [('_CHECKPOINTABLE_OBJECT_GRAPH', []), ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', []), ('tr2/v/.ATTRIBUTES/VARIABLE_VALUE', [])]\n"
     ]
    }
   ],
   "source": [
    "deleting(tr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable management also means possibly aggregating variables into various containers.\n",
    "\n",
    "Intuitive Python `list` and `dict` structures can be transparently employed through the `trackable` mechanism.\n",
    "\n",
    "Using our below-modified function to print our variables in our `containers':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def containers(tr3):\n",
    "    c = tf.train.Checkpoint(tr3=tr3)\n",
    "    m = tf.train.CheckpointManager(c, '/tmp/q/trackable', max_to_keep=2)\n",
    "    m.save()\n",
    "    vs = tf.train.list_variables(m.latest_checkpoint)\n",
    "    print(f'containers: {vs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as mentioned above, we can intuitively collect variables into either `list`s or `dict`s.\n",
    "\n",
    "And the patterns used for naming the thus aggregated variables are just as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "containers: [('_CHECKPOINTABLE_OBJECT_GRAPH', []), ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', []), ('tr3/br_dict/br3/v/.ATTRIBUTES/VARIABLE_VALUE', []), ('tr3/br_list/0/v/.ATTRIBUTES/VARIABLE_VALUE', []), ('tr3/br_list/1/v/.ATTRIBUTES/VARIABLE_VALUE', [])]\n"
     ]
    }
   ],
   "source": [
    "tr3 = tracking.AutoTrackable()\n",
    "br1 = tracking.AutoTrackable()\n",
    "br1.v = tf.Variable(5)\n",
    "br2 = tracking.AutoTrackable()\n",
    "br2.v = tf.Variable(5)\n",
    "tr3.br_list = [br1, br2]\n",
    "br3 = tracking.AutoTrackable()\n",
    "br3.v = tf.Variable(5)\n",
    "tr3.br_dict = {'br3': br3}\n",
    "containers(tr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks rely on sharing persisted trainable weights, TF variables in our case, to express interdependencies.\n",
    "\n",
    "Variable sharing was ad-hoc, only name-based and with a global scope before.\n",
    "\n",
    "As Python has extensive native support for managing easily sharable references to its objects, this fundamental problem gets an intuitive solution with the new trackable architecture.\n",
    "\n",
    "As expected, sharing variables now is natural and also safe, as it uses references instead of error-prone strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharing(tr3):\n",
    "    c = tf.train.Checkpoint(tr3=tr3)\n",
    "    m = tf.train.CheckpointManager(c, '/tmp/q/trackable', max_to_keep=2)\n",
    "    c.restore(m.latest_checkpoint).assert_consumed()\n",
    "    v1 = tr3.br_list[0].v\n",
    "    v2 = tr3.br_list[1].v\n",
    "    vd1 = tr3.br_dict['br1'].v\n",
    "    vd2 = tr3.br_dict['br2'].v\n",
    "    vd3 = tr3.br_dict['br3'].v\n",
    "    print(f'all fives: {v1.numpy()}, {v2.numpy()}, {vd3.numpy()}')\n",
    "    print(f'shared too: {vd1.numpy()}, {vd2.numpy()}')\n",
    "    v1.assign_add(5)\n",
    "    v2.assign_add(5)\n",
    "    vd3.assign_add(5)\n",
    "    m.save()\n",
    "    vs = tf.train.list_variables(m.latest_checkpoint)\n",
    "    print(f'shared not repeated: {vs}')\n",
    "    v1.assign_add(-10)\n",
    "    v2.assign_add(-10)\n",
    "    vd3.assign_add(-10)\n",
    "    print(f'all zeros: {v1.numpy()}, {v2.numpy()}, {vd3.numpy()}')\n",
    "    print(f'shared too: {vd1.numpy()}, {vd2.numpy()}')\n",
    "    c2 = tf.train.Checkpoint(tr3=tr3)\n",
    "    m = tf.train.CheckpointManager(c2, '/tmp/q/trackable', max_to_keep=2)\n",
    "    c2.restore(m.latest_checkpoint).assert_consumed()\n",
    "    print(f'all tens: {v1.numpy()}, {v2.numpy()}, {vd3.numpy()}')\n",
    "    print(f'shared too: {vd1.numpy()}, {vd2.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persisted shared variables are not duplicated in checkpoints. And when checkpoints are restored or reloaded, the in-memory sharing of variables is also re-established.\n",
    "\n",
    "Updates to our shared variables can be easily verified just as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all fives: 5, 5, 5\n",
      "shared too: 5, 5\n",
      "shared not repeated: [('_CHECKPOINTABLE_OBJECT_GRAPH', []), ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', []), ('tr3/br_dict/br3/v/.ATTRIBUTES/VARIABLE_VALUE', []), ('tr3/br_list/0/v/.ATTRIBUTES/VARIABLE_VALUE', []), ('tr3/br_list/1/v/.ATTRIBUTES/VARIABLE_VALUE', [])]\n",
      "all zeros: 0, 0, 0\n",
      "shared too: 0, 0\n",
      "all tens: 10, 10, 10\n",
      "shared too: 10, 10\n"
     ]
    }
   ],
   "source": [
    "tr3.br_dict = {'br1': br1, 'br2': br2, 'br3': br3}\n",
    "sharing(tr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable management also means possible encapsulation.\n",
    "\n",
    "The new `Module` objects build on `AutoTrackable` to extend Python's familiar `class`-based encapsulation mechanism.\n",
    "\n",
    "The also supported explicit name scoping of modules allows the reuse of module classes, as instances of the same class would need to be generically counted otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(tf.Module):\n",
    "    sub = None\n",
    "\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        with self.name_scope:\n",
    "            self.v = tf.Variable(1, name='m_v')\n",
    "\n",
    "    def __str__(self):\n",
    "        s = f'n: {self.name}, v: {self.v.numpy()}'\n",
    "        if self.sub:\n",
    "            s += f', s: ({self.sub})'\n",
    "        return s\n",
    "\n",
    "    @tf.Module.with_name_scope\n",
    "    def __call__(self):\n",
    "        if self.sub is None:\n",
    "            y = tf.constant(100)\n",
    "        else:\n",
    "            y = self.sub()\n",
    "        y = tf.math.add(y, self.v)\n",
    "        self.v.assign(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building hierarchies of modules, TF provided convenience methods also allow for recursively collecting the \"layered\" variables. This is essential for computing gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modules(mod):\n",
    "    vs = [v.name for v in mod.variables]\n",
    "    ms = [m.name for m in mod.submodules]\n",
    "    print(f'mod variables: {vs}, submodules: {ms}')\n",
    "    c = tf.train.Checkpoint(module=mod)\n",
    "    m = tf.train.CheckpointManager(c, '/tmp/q/trackable', max_to_keep=2)\n",
    "    mod()\n",
    "    print(mod)\n",
    "    m.save()\n",
    "    mod()\n",
    "    print(mod)\n",
    "    p = m.latest_checkpoint\n",
    "    vs = tf.train.list_variables(p)\n",
    "    print(f'containers: {vs}')\n",
    "    c.restore(p)\n",
    "    print(f'restored: {mod}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our module class and our handy printing function, we can now build a basic nested hierarchy of 3 layered modules.\n",
    "\n",
    "Printing our \"one branch tree\" shows both the name-based hierarchy and the Python-object or topological \"checkpoint\" hierarchy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mod variables: ['m1/m_v:0', 'm2/m_v:0', 'm3/m_v:0'], submodules: ['m2', 'm3']\n",
      "n: m1, v: 103, s: (n: m2, v: 102, s: (n: m3, v: 101))\n",
      "n: m1, v: 406, s: (n: m2, v: 303, s: (n: m3, v: 201))\n",
      "containers: [('_CHECKPOINTABLE_OBJECT_GRAPH', []), ('module/sub/sub/v/.ATTRIBUTES/VARIABLE_VALUE', []), ('module/sub/v/.ATTRIBUTES/VARIABLE_VALUE', []), ('module/v/.ATTRIBUTES/VARIABLE_VALUE', []), ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', [])]\n",
      "restored: n: m1, v: 103, s: (n: m2, v: 102, s: (n: m3, v: 101))\n"
     ]
    }
   ],
   "source": [
    "mod1 = Module('m1')\n",
    "mod1.sub = Module('m2')\n",
    "mod1.sub.sub = Module('m3')\n",
    "modules(mod1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is the API for consistently reasoning about the interconnected network of components. It also visibly splits the two distinct, building vs. executing, phases of our component \"graphs\".\n",
    "\n",
    "The `functional` Keras, as opposed to either the `sequential` or the `subclassed` flavors, has the most pre-packaged features to assist us with our neural networks. We aim to use it throughout our blogs.\n",
    "\n",
    "Keras `layer`s, as well-defined encapsulating components, build on the previously used `module`s to manage variable persistence.\n",
    "\n",
    "Hence, the previous `module`s example is almost identical to the below shown \"Keras layers\" version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, sub=None, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.sub = sub\n",
    "\n",
    "    def __str__(self):\n",
    "        s = f'n: {self.name}, v: {self.v.numpy()}'\n",
    "        if self.sub:\n",
    "            s += f', s: ({self.sub})'\n",
    "        return s\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.v = self.add_weight(name='l_v',\n",
    "                                 shape=[],\n",
    "                                 dtype=tf.int32,\n",
    "                                 initializer=tf.ones_initializer)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.sub is None:\n",
    "            y = x\n",
    "        else:\n",
    "            y = self.sub(x)\n",
    "        y = tf.math.add(y, self.v)\n",
    "        self.v.assign(tf.reduce_sum(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, after adjusting our helper to print the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(mod, lay):\n",
    "    print(mod.summary())\n",
    "    vs = [v.name for v in mod.variables]\n",
    "    ts = [t.name for t in mod.trainable_variables]\n",
    "    ms = [m.name for m in mod.submodules]\n",
    "    print(f'lay variables: {vs}, trainables: {ts}, submodules: {ms}')\n",
    "    d = tf.constant([100, 100])\n",
    "    mod(d)\n",
    "    print(lay)\n",
    "    c = tf.train.Checkpoint(model=mod)\n",
    "    m = tf.train.CheckpointManager(c, '/tmp/q/trackable', max_to_keep=2)\n",
    "    m.save()\n",
    "    mod(d)\n",
    "    print(lay)\n",
    "    p = m.latest_checkpoint\n",
    "    vs = tf.train.list_variables(p)\n",
    "    print(f'containers: {vs}')\n",
    "    c.restore(p)\n",
    "    print(f'restored: {lay}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally arrive at the most simple Keras model.\n",
    "\n",
    "It uses just 3 scalar variables to showcase the underlying already tried and used persistence management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"m2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "l1 (Layer)                   (1, None)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "lay variables: ['l1/l_v:0', 'l1/l2/l_v:0', 'l1/l2/l3/l_v:0'], trainables: ['l1/l_v:0', 'l1/l2/l_v:0', 'l1/l2/l3/l_v:0'], submodules: ['input_1', 'l1', 'l2', 'l3']\n",
      "n: l1, v: 206, s: (n: l2, v: 204, s: (n: l3, v: 202))\n",
      "n: l1, v: 1424, s: (n: l2, v: 1012, s: (n: l3, v: 604))\n",
      "containers: [('_CHECKPOINTABLE_OBJECT_GRAPH', []), ('model/layer_with_weights-0/l_v/.ATTRIBUTES/VARIABLE_VALUE', []), ('model/layer_with_weights-0/sub/l_v/.ATTRIBUTES/VARIABLE_VALUE', []), ('model/layer_with_weights-0/sub/sub/l_v/.ATTRIBUTES/VARIABLE_VALUE', []), ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', [])]\n",
      "restored: n: l1, v: 206, s: (n: l2, v: 204, s: (n: l3, v: 202))\n"
     ]
    }
   ],
   "source": [
    "ins = [tf.keras.Input(shape=(), dtype=tf.int32)]\n",
    "lay = Layer(name='l1', sub=Layer(name='l2', sub=Layer(name='l3')))\n",
    "outs = [lay(ins)]\n",
    "mod2 = tf.keras.Model(name='m2', inputs=ins, outputs=outs)\n",
    "models(mod2, lay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, even the simplest model can be overwhelming when expressed only textually.\n",
    "\n",
    "TensorBoard is an accompanying tool that can help us in \"picturing\" the nested component graphs.\n",
    "\n",
    "As \"a picture is worth a thousand words\", `summary` data for TB is generated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(tracer):\n",
    "    s = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    d = f'/tmp/q/logs/func/{s}'\n",
    "    w = tf.summary.create_file_writer(d)\n",
    "    tf.summary.trace_on(graph=True)  # , profiler=True)\n",
    "    tracer()\n",
    "    with w.as_default():\n",
    "        tf.summary.trace_export(name=\"trace\", step=0, profiler_outdir=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that our trivially simple Keras model still implements data-driven Python recursion.\n",
    "\n",
    "The new `autograph` functionality allows us to use such intuitive, native expressions instead of the usual, but more cumbersome, TF \"graph ops\".\n",
    "\n",
    "Autograph code generation is invoked with the `tf.function` Python decorator. A later blog will highlight the most impressive features of this new approach to defining ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tracer2():\n",
    "    return mod2(tf.constant([100, 100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see the TB generated summaries, including the picture of our graph, we need to load the extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we generate the TB summaries by calling our `tracer` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph(tracer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can view the zoom-able and clickable TB graph.\n",
    "\n",
    "If you haven't run the code, an already generated graph is [here](./trackable.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%tensorboard --logdir /tmp/q/logs/func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our blog. For using the new GPU-related functionality, please click on our next blog."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.qpy)",
   "language": "python",
   "name": "qpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
