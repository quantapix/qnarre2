{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Keras Layers Without The Drawbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog we continue to train our computer to \"understand\" elementary symbolic arithmetic.\n",
    "\n",
    "We slightly change our approach however. Instead of having fixed input/context for our encoder/decoder stacks, we follow the idea of \"sliding contexts\" from this [paper](https://arxiv.org/pdf/1901.02860.pdf).\n",
    "\n",
    "In addition, we continue to architect our model with a mixture of \"validated\" Keras `layers` as well as light-weight `Modules` containing bare TF ops.\n",
    "\n",
    "Our objective is to ultimately arrive at a model representable by the [graph](./custom.pdf).\n",
    "\n",
    "Just as before, we need to prep our environment to run any meaningful code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import dataset as qd\n",
    "import layers as ql\n",
    "ks = tf.keras\n",
    "kl = ks.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, we need to increase our dataset slightly as the training steps are becoming more meaningful.\n",
    "\n",
    "Calling the `dump_dset` function with a parameters instance will update our stored sharded binary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dset(ps):\n",
    "    ps.max_val = 10000\n",
    "    ps.num_samples = 1000  # 100000\n",
    "    ps.num_shards = 10\n",
    "    fs = [f for f in qd.dump(ps)]\n",
    "    ps.dim_batch = 100\n",
    "    for i, _ in enumerate(qd.load(ps, fs).map(adapter)):\n",
    "        pass\n",
    "    print(f'dumped {i} batches of {ps.dim_batch} samples each')\n",
    "    return fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For verification purposes, loading our already created meta data from the sources gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ', ':', '|', 'x', 'y', '=', ',', '+', '-', '*', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
      "0 1 2\n"
     ]
    }
   ],
   "source": [
    "print(qd.vocab)\n",
    "print(qd.SPC, qd.SEP, qd.STP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to expand our previously used `formatter`.\n",
    "\n",
    "As we intend to concatenate subsequent inputs in our \"sliding context\", we need to end the result feature, `res`, of our samples with our `STP = \"|\"` token.\n",
    "\n",
    "We have started to use `tf.debugging.assert`s to increase our confidence in the correctness of our data. Later we will be able to switch these out with the familiar Python `asserts`.\n",
    "\n",
    "Our `formatter` comes with an other significant adjustment.\n",
    "\n",
    "We intend to feed both our `encoder` and our `decoder` with inputs. Namely, the encoder gets the concatenated `defs` and `op` features, while the decoder gets either a fully or a partially blanked `res`.\n",
    "\n",
    "Our dataset will supply an `enc`, a `dec` and a `tgt` (the full correct result of the math expression in the sample) tensors. The `rand_blank` function does the quick (inline) random blanking, or masking, of the arithmetic result to be fed into our `decoder` as the `des` tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def formatter(d):\n",
    "    ds = tf.RaggedTensor.from_sparse(d['defs'])\n",
    "    n = ds.nrows()\n",
    "    os = tf.RaggedTensor.from_sparse(d['op'])\n",
    "    tf.debugging.assert_equal(n, os.nrows())\n",
    "    ss = tf.fill([n, 1], qd.SEP)\n",
    "    enc = tf.concat([ds, ss, os, ss], axis=1)\n",
    "    rs = tf.RaggedTensor.from_sparse(d['res'])\n",
    "    tf.debugging.assert_equal(n, rs.nrows())\n",
    "    tgt = tf.concat([rs, tf.fill([n, 1], qd.STP)], axis=1)\n",
    "\n",
    "    def rand_blank(x):\n",
    "        y = x.flat_values\n",
    "        mv = tf.shape(y)[0]\n",
    "        s = mv // 2\n",
    "        i = tf.random.uniform([s], maxval=mv, dtype=tf.int32)[:, None]\n",
    "        y = tf.tensor_scatter_nd_update(y, i, tf.zeros([s], dtype=tf.int32))\n",
    "        return x.with_flat_values(y)\n",
    "\n",
    "    return {'enc': enc, 'dec': rand_blank(tgt), 'tgt': tgt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for our dataset to be usable, we also need to update our `adapter`.\n",
    "\n",
    "We continue to split our input ragged tensors into their components, and as we now have 3 ragged inputs: `enc`, `dec` and `tgt`, the total number of dense input tensors to our model will be 6.\n",
    "\n",
    "The adapter needs to also supply our `tgt` dense tensor to the canned `loss` and `metrics` components that drive the gradient calculations.\n",
    "\n",
    "In addition, we chose to add `tgt`, or its two components, to our inputs as well. This duplication gives us the chance of feeding correct arithmetic results into our \"sliding context\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def adapter(d):\n",
    "    enc, dec, tgt = d['enc'], d['dec'], d['tgt']\n",
    "    return (\n",
    "        (\n",
    "            enc.flat_values,\n",
    "            enc.row_splits,\n",
    "            dec.flat_values,\n",
    "            dec.row_splits,\n",
    "            tgt.flat_values,\n",
    "            tgt.row_splits,\n",
    "        ),\n",
    "        tgt.to_tensor(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new dataset creator function, `dset_for` is as follows.\n",
    "\n",
    "We have added an optionally overridable `adapter` argument to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dset_for(ps, adapter=adapter):\n",
    "    ds = tf.data.TFRecordDataset(list(qd.files(ps)))\n",
    "    ds = ds.take(100).batch(ps.dim_batch)\n",
    "    fs = {\n",
    "        'defs': tf.io.VarLenFeature(tf.int64),\n",
    "        'op': tf.io.VarLenFeature(tf.int64),\n",
    "        'res': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    ds = ds.map(lambda x: tf.io.parse_example(x, fs)).map(qd.caster)\n",
    "    return ds.map(formatter).map(adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we now have 3 pairs of input tensors, that we need to convert back into `RaggedTensor`s, we quickly add a `ToRagged` convenience layer that can be seamlessly eliminated once the Keras `Input`s start properly supporting the `ragged=True` keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToRagged(kl.Layer):\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        ys = []\n",
    "        for i in range(3):\n",
    "            i *= 2\n",
    "            fv, rs = x[i:i + 2]\n",
    "            ys.append(tf.RaggedTensor.from_row_splits(fv, rs))\n",
    "        return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Frames` layer is the new significant addition to our code.\n",
    "\n",
    "With every new encoder input sequence of tokens `xe`, it first concatenates the `prev` stored context with `xe` and then stores the result in `ye`.\n",
    "\n",
    "Then it updates the `prev` variable with the concatenation of `ye` and the passed in correct arithmetic result `xt`. The resulting `prev` is to be used in the next cycle.\n",
    "\n",
    "The computations are slightly more complex due to using the raggedness of the inputs to satisfy the continuous, seamlessly \"sliding context\" requirement.\n",
    "\n",
    "The layer also returns the \"row_lengths\" tensors for both `enc` and `dec` inputs. They will be used later for propagating the input token sequences' \"raggedness\".\n",
    "\n",
    "The entire `Frames` layer works exclusively with tokens, as we don't want to keep stale embedding calculations around in our \"sliding context\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frames(ql.Layer):\n",
    "    def __init__(self, ps):\n",
    "        super().__init__(ps, dtype=tf.int32)  # , dynamic=True)\n",
    "        s = (ps.dim_batch, ps.width_enc)\n",
    "        kw = dict(initializer='zeros', trainable=False, use_resource=True)\n",
    "        self.prev = self.add_weight('prev', shape=s, **kw)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        xe, xd, xt = x\n",
    "        ye = tf.concat([self.prev, xe], axis=1)\n",
    "        el = tf.cast(xe.row_lengths(), dtype=tf.int32)\n",
    "        ye = tf.gather_nd(ye, self.calc_idxs(el))\n",
    "        c = self.ps.width_dec - xd.bounding_shape(axis=1, out_type=tf.int32)\n",
    "        yd = tf.pad(xd.to_tensor(), [[0, 0], [0, c]])\n",
    "        dl = tf.cast(xd.row_lengths(), dtype=tf.int32)\n",
    "        p = tf.concat([ye, xt], axis=1)\n",
    "        tl = tf.cast(xt.row_lengths(), dtype=tf.int32)\n",
    "        p = tf.gather_nd(p, self.calc_idxs(tl))\n",
    "        self.prev.assign(p)\n",
    "        return [ye, el, yd, dl]\n",
    "\n",
    "    def calc_idxs(self, lens):\n",
    "        b, w = self.ps.dim_batch, self.ps.width_enc\n",
    "        y = tf.broadcast_to(tf.range(b)[:, None], [b, w])\n",
    "        i = tf.range(w)[None, ] + lens[:, None]\n",
    "        y = tf.stack([y, i], axis=2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our `Frames` layer returns fixed-width dense tensors once again, we can re-adjust our carried-over `Embed` layer to use the straight `embedding_lookup` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embed(ql.Layer):\n",
    "    def __init__(self, ps):\n",
    "        super().__init__(ps)\n",
    "        s = (ps.dim_vocab, ps.dim_hidden)\n",
    "        self.emb = self.add_weight('emb', shape=s)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        y, lens = x\n",
    "        y = tf.nn.embedding_lookup(self.emb, y)\n",
    "        y *= y.shape[-1]**0.5\n",
    "        return [y, lens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the `Encode` and `Decode` layers with the addition of the `tf.function` decorators for the `call` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encode(ql.Layer):\n",
    "    def __init__(self, ps):\n",
    "        super().__init__(ps)\n",
    "        self.width = ps.width_enc\n",
    "        self.encs = [Encoder(self, f'enc_{i}') for i in range(ps.dim_stacks)]\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        y = x\n",
    "        for e in self.encs:\n",
    "            y = e(y)\n",
    "        return y\n",
    "\n",
    "class Decode(ql.Layer):\n",
    "    def __init__(self, ps):\n",
    "        super().__init__(ps)\n",
    "        self.width = ps.width_dec\n",
    "        self.decs = [Decoder(self, f'dec_{i}') for i in range(ps.dim_stacks)]\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        y, ye = x[:-1], x[-1]\n",
    "        for d in self.decs:\n",
    "            y = d(y + [ye])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `Debed` layer is also largely a carry-over, with the adjustment for the now fixed-width tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debed(ql.Layer):\n",
    "    def __init__(self, ps):\n",
    "        super().__init__(ps)\n",
    "        self.dbd = Dense(self, 'dbd', [ps.dim_hidden, ps.dim_vocab])\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        y, lens = x\n",
    "        s = tf.shape(y)\n",
    "        y = tf.reshape(y, [s[0] * s[1], -1])\n",
    "        y = self.dbd(y)\n",
    "        y = tf.reshape(y, [s[0], s[1], -1])\n",
    "        y = y[:, :tf.math.reduce_max(lens), :]\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the `Encoder` and `Decoder` modules with the addition of the `tf.function` decorators for the `__call__` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.Module):\n",
    "    def __init__(self, layer, name):\n",
    "        super().__init__(name=name)\n",
    "        with self.name_scope:\n",
    "            self.reflect = Attention(layer, 'refl')\n",
    "            self.conclude = Conclusion(layer, 'conc')\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        y = x\n",
    "        y = self.reflect(y + [y[0]])\n",
    "        y = self.conclude(y)\n",
    "        return y\n",
    "\n",
    "class Decoder(tf.Module):\n",
    "    def __init__(self, layer, name):\n",
    "        super().__init__(name=name)\n",
    "        with self.name_scope:\n",
    "            self.reflect = Attention(layer, 'refl')\n",
    "            self.consider = Attention(layer, 'cnsd')\n",
    "            self.conclude = Conclusion(layer, 'conc')\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        y, ye = x[:-1], x[-1]\n",
    "        y = self.reflect(y + [y[0]])\n",
    "        y = self.consider(y + [ye])\n",
    "        y = self.conclude(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same applies to our new `Attention` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.Module):\n",
    "    def __init__(self, layer, name):\n",
    "        super().__init__(name=name)\n",
    "        h = layer.ps.dim_hidden\n",
    "        self.scale = 1 / (h**0.5)\n",
    "        with self.name_scope:\n",
    "            self.q = layer.add_weight('q', shape=(h, h))\n",
    "            self.k = layer.add_weight('k', shape=(h, h))\n",
    "            self.v = layer.add_weight('v', shape=(h, h))\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        x, lens, ctx = x\n",
    "        off = tf.math.reduce_max(lens)\n",
    "        q = tf.einsum('bni,ij->bnj', x[:, -off:, :], self.q)\n",
    "        k = tf.einsum('bni,ij->bnj', ctx, self.k)\n",
    "        y = tf.einsum('bni,bmi->bnm', q, k)\n",
    "        # use lens\n",
    "        y = tf.nn.softmax(y * self.scale)\n",
    "        v = tf.einsum('bni,ij->bnj', ctx, self.v)\n",
    "        y = tf.einsum('bnm,bmi->bni', y, v)\n",
    "        y = tf.concat([x[:, :-off, :], y], axis=1)\n",
    "        return [y, lens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same applies to our new `Conclusion` module as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conclusion(tf.Module):\n",
    "    def __init__(self, layer, name):\n",
    "        super().__init__(name=name)\n",
    "        self.layer = layer\n",
    "        ps = layer.ps\n",
    "        w = layer.width * ps.dim_hidden\n",
    "        with self.name_scope:\n",
    "            s = [w, ps.dim_dense]\n",
    "            self.inflate = Dense(layer, 'infl', s, activation='relu')\n",
    "            s = [ps.dim_dense, w]\n",
    "            self.deflate = Dense(layer, 'defl', s, bias=False)\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        y, lens = x\n",
    "        w = self.layer.width\n",
    "        d = self.layer.ps.dim_hidden\n",
    "        y = tf.reshape(y, [-1, w * d])\n",
    "        y = self.inflate(y)\n",
    "        y = self.deflate(y)\n",
    "        y = tf.reshape(y, [-1, w, d])\n",
    "        return [y, lens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add the `tf.function` decorator to our `Dense` module, we simply inherit from the previous version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(ql.Dense):\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        return super().__call__(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model instance needs to be updated as well to use the newly defined components.\n",
    "\n",
    "Another significant change is the addition of the \"row_lengths\" tensor (received directly from the ragged tensors) to all the now fixed-width input and output dense tensors.\n",
    "\n",
    "Once again, we were able to return to using dense tensors for our inputs, despite the \"raggedness\" of our samples, because we adopted the \"sliding context\" strategy, thus smoothly concatenating an entire \"history\" of inputs and correct arithmetic results, into our \"working set\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for(ps):\n",
    "    x = [ks.Input(shape=(), dtype='int32'), ks.Input(shape=(), dtype='int64')]\n",
    "    x += [ks.Input(shape=(), dtype='int32'), ks.Input(shape=(), dtype='int64')]\n",
    "    x += [ks.Input(shape=(), dtype='int32'), ks.Input(shape=(), dtype='int64')]\n",
    "    y = ToRagged()(x)\n",
    "    y = Frames(ps)(y)\n",
    "    embed = Embed(ps)\n",
    "    ye = Encode(ps)(embed(y[:2]))\n",
    "    yd = Decode(ps)(embed(y[2:]) + [ye[0]])\n",
    "    y = Debed(ps)(yd)\n",
    "    m = ks.Model(inputs=x, outputs=y)\n",
    "    m.compile(optimizer=ps.optimizer, loss=ps.loss, metrics=[ps.metric])\n",
    "    print(m.summary())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our parameters need to be expanded with the addition of the values for the now fixed widths of both our `encoder` and `decoder` stacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    dim_batch=5,\n",
    "    dim_dense=150,\n",
    "    dim_hidden=6,\n",
    "    dim_stacks=2,\n",
    "    dim_vocab=len(qd.vocab),\n",
    "    loss=ks.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metric=ks.metrics.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    num_epochs=5,\n",
    "    num_shards=2,\n",
    "    optimizer=ks.optimizers.Adam(),\n",
    "    width_dec=15,\n",
    "    width_enc=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By firing up our training session, we can confirm the model's layers and connections. The listing of a short session follows.\n",
    "\n",
    "We can easily adjust the parameters to tailor the length of the sessions to our objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "to_ragged_1 (ToRagged)          [(None, None), (None 0           input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "frames_1 (Frames)               [(5, 25), (None,), ( 125         to_ragged_1[0][0]                \n",
      "                                                                 to_ragged_1[0][1]                \n",
      "                                                                 to_ragged_1[0][2]                \n",
      "__________________________________________________________________________________________________\n",
      "embed_1 (Embed)                 multiple             120         frames_1[0][0]                   \n",
      "                                                                 frames_1[0][1]                   \n",
      "                                                                 frames_1[0][2]                   \n",
      "                                                                 frames_1[0][3]                   \n",
      "__________________________________________________________________________________________________\n",
      "encode_1 (Encode)               [(None, 25, 6), (Non 90516       embed_1[0][0]                    \n",
      "                                                                 embed_1[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decode_1 (Decode)               [(None, 15, 6), (Non 54732       embed_1[1][0]                    \n",
      "                                                                 embed_1[1][1]                    \n",
      "                                                                 encode_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "debed_1 (Debed)                 (None, None, None)   140         decode_1[0][0]                   \n",
      "                                                                 decode_1[0][1]                   \n",
      "==================================================================================================\n",
      "Total params: 145,633\n",
      "Trainable params: 145,508\n",
      "Non-trainable params: 125\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 20s 1s/step - loss: 2.6308 - sparse_categorical_crossentropy: 2.6164\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.1488 - sparse_categorical_crossentropy: 2.1325\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.8967 - sparse_categorical_crossentropy: 1.8844\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.7398 - sparse_categorical_crossentropy: 1.7248\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.5818 - sparse_categorical_crossentropy: 1.5736\n"
     ]
    }
   ],
   "source": [
    "ps = qd.Params(**params)\n",
    "import masking as qm\n",
    "qm.main_graph(ps, dset_for(ps), model_for(ps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our TensorBoard `callback` in place, the model's `fit` method will generate the standard summaries that TB can conveniently visualize.\n",
    "\n",
    "If you haven't run the code below, an already generated graph is [here](./custom.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir /tmp/q/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also switch over to the new `eager` execution mode.\n",
    "\n",
    "Once again, this is particularly convenient for experimentation, as all ops are immediately executed. And here is a much shortened `eager` session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ragged as qr\n",
    "# qr.main_eager(ps, dset_for(ps), model_for(ps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our blog, please see how to use the `autograph` features with our model by clicking on the next blog."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
