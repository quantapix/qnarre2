{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many Smaller GPUs: Elegant In-Model Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs (and TPUs) are no doubt one of our most critical resources when running neural networks.\n",
    "\n",
    "GPUs have strict capacities and limits as physical resources. When using servers with many smaller GPUs, we often ran into the inherent physical limitations of our equipment.\n",
    "\n",
    "Laying out a possibly large model across many smaller GPUs has thus become a requirement for us. This blog presents a few basic steps in that direction.\n",
    "\n",
    "The outlined model can also be used to effectively test more complex and custom GPU allocation strategies.\n",
    "\n",
    "Our objective here is to arrive at training a model representable by the [graph](./gpus.pdf).\n",
    "\n",
    "Just as before, we need to prep our environment to run any meaningful code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a few convenient aliases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = tf.keras\n",
    "kl = ks.layers\n",
    "cfg = tf.config.experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any effective and generalizable allocation strategy, we need to be able to reason about our resources uniformly.\n",
    "\n",
    "We start with the new TF functionality of partitioning our physical GPUs into custom-sized, and thus easily \"normalizable\", virtual GPUs.\n",
    "\n",
    "The components, or layers of our models, can then expect the ids of the properly sized, or allocated, virtual GPUs.\n",
    "\n",
    "Given the parameter-driven \"resource\" requirements of our layers, we can also develop heuristics for partitioning and allocating the physical devices before starting a training session. Such heuristics are beyond the scope of this blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices: ['/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7', '/job:localhost/replica:0/task:0/device:GPU:8', '/job:localhost/replica:0/task:0/device:GPU:9', '/job:localhost/replica:0/task:0/device:GPU:10', '/job:localhost/replica:0/task:0/device:GPU:11']\n"
     ]
    }
   ],
   "source": [
    "devs = ((None, ), (1000, 1000, 1000, 1000, 1000, 1000), (1000, 1000, 1000, 1000, 1000, 1000))\n",
    "cfg.set_visible_devices(cfg.get_visible_devices('CPU')[:1], 'CPU')\n",
    "cfg.set_visible_devices(cfg.get_visible_devices('GPU')[:len(devs) - 1], 'GPU')\n",
    "for d, ms in zip(cfg.get_visible_devices(), devs):\n",
    "    vs = [cfg.VirtualDeviceConfiguration(m) for m in ms]\n",
    "    cfg.set_virtual_device_configuration(d, vs)\n",
    "devs = cfg.list_logical_devices('CPU')\n",
    "devs += cfg.list_logical_devices('GPU')\n",
    "print('devices:', [d.name for d in devs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn off \"soft\" allocation for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_soft_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we develop here builds on a configurable \"stack\" of identical layers.\n",
    "\n",
    "A most basic, custom `dense` layer class is all we need as the stack's repeated component.\n",
    "\n",
    "We aim to \"lay\" this stack on its side, and onto our virtual GPUs, as a functional, forward-backward propagating pipeline that could now fit in our combined GPU-space.\n",
    "\n",
    "Each layer of the stack would, therefore, use a predetermined, or heuristically pre-calculated, virtual GPU `idx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(kl.Layer):\n",
    "    def __init__(self, i, ps, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.idx = min(i + 1, len(devs) - 1)\n",
    "        self.ps = ps\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        s = input_shape[-1]\n",
    "        with tf.device(devs[self.idx].name):\n",
    "            self.w = self.add_weight(name='l_w', shape=(s, s))\n",
    "            self.b = self.add_weight(name='l_b', shape=(s, ))\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        with tf.device(devs[self.idx].name):\n",
    "            y = tf.einsum('bi,ij->bj', x, self.w) + self.b\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic `sequential` Keras model will suffice as the container of our stack.\n",
    "\n",
    "Once our input, as well as the output, is shaped, we simply chain our chosen number of layers together, in the middle of our basic `sequential` model.\n",
    "\n",
    "The Keras model's `summary` method is handy to confirm our model is laid out just as intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for(ps):\n",
    "    m = ks.Sequential()\n",
    "    m.add(kl.Dense(ps.dim_hidden, input_dim=ps.dim_input, name='in'))\n",
    "    for i in range(ps.num_layers):\n",
    "        m.add(Layer(i, ps, name=f'lay_{i}'))\n",
    "    m.add(kl.Dense(ps.dim_input, name='out'))\n",
    "    m.compile(optimizer=ps.optimizer(), loss=ps.loss(), metrics=[ps.metrics()])\n",
    "    print(m.summary())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can run our model, we need to establish our parameters, the various dimensions and other attributes we want to use to shape the training.\n",
    "\n",
    "A simple Python `dict` works best to keep things organized, unique and also sorted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    dim_hidden=1000,\n",
    "    dim_input=100,\n",
    "    loss=ks.losses.MeanAbsoluteError,\n",
    "    metrics=ks.metrics.MeanAbsoluteError,\n",
    "    num_layers=10,\n",
    "    optimizer=ks.optimizers.SGD,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drawback of string keyed `dict`s is just that, the strings can have typos in them and hundreds of potentially misnamed parameters, later on, will certainly cause unnecessary confusion.\n",
    "\n",
    "Python's automatically verified native `attribute`s come to the rescue once again.\n",
    "\n",
    "Here is a simple, straightforward and functional `Params` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self, **kw):\n",
    "        for k, v in kw.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our `Params` instance and a truly handy training data set (with testing and verification all built-in) in just one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = Params(**params)\n",
    "import numpy as np\n",
    "d = np.ones((100, ps.dim_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to compile our model. And, just as expected, the `summary` of the model shows that it has over 10 million weights.\n",
    "\n",
    "The initial values of the weights are randomly picked. Through training, we bring these arbitrary values \"inline\" through millions of multiplications and additions executed by our many virtual GPUs, only to verify that our input `ones` are, in fact, just a series of `1`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 1000)              101000    \n",
      "_________________________________________________________________\n",
      "lay_0 (Layer)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "lay_1 (Layer)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "lay_2 (Layer)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "lay_3 (Layer)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "lay_4 (Layer)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "lay_5 (Layer)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "lay_6 (Layer)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "lay_7 (Layer)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "lay_8 (Layer)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "lay_9 (Layer)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 100)               100100    \n",
      "=================================================================\n",
      "Total params: 10,211,100\n",
      "Trainable params: 10,211,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = model_for(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model gives us the familiar Keras output, showing a nice convergence of a trivial problem across easily configurable GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 17ms/sample - loss: 0.4796 - mean_absolute_error: 0.4796\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.2872 - mean_absolute_error: 0.2872\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.2414 - mean_absolute_error: 0.2414\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.2252 - mean_absolute_error: 0.2252\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.1988 - mean_absolute_error: 0.1988\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.1984 - mean_absolute_error: 0.1984\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.1734 - mean_absolute_error: 0.1734\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.1551 - mean_absolute_error: 0.1551\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.1719 - mean_absolute_error: 0.1719\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.1527 - mean_absolute_error: 0.1527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc760cdf518>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "ld = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "ld = f'/tmp/logs/{ld}'\n",
    "cs = [ks.callbacks.TensorBoard(log_dir=ld, histogram_freq=1)]\n",
    "m.fit(d, d, callbacks=cs, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's fire up TensorBoard and visually confirm that our stack of \"dense\" layers is connected just as expected.\n",
    "\n",
    "If you haven't run the code, an already generated graph is [here](./gpus.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir /tmp/q/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our blog, please see how to use the new dataset functionality by clicking on the next blog."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.qpy)",
   "language": "python",
   "name": "qpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
