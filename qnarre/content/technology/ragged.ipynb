{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragged Tensors For Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RaggedTensor`s are a newly added feature in TF. They intend to cleanly and efficiently solve the previously mentioned \"uneven sequence-length\" problem.\n",
    "\n",
    "While easily convertible, they are different from the more general `SparseTensor`s, as they only allow \"ragged edges\".\n",
    "\n",
    "From an implementation point of view, `RaggedTensors` are efficiently represented as `composite tensor`s consisting of 1) a packed sequence of values and 2) a list of indices (effectively \"row lengths\").\n",
    "\n",
    "These new composite tensors are purpose-fitted to our sample text processing problem.\n",
    "\n",
    "One significant advantage of their specific design is the fluid nature of their \"duality\". On one hand, they can be viewed just as a simple vector of values, for efficient graph ops. On the other hand, they can be used as handy \"masks\", to selectively extract just the right values from dense tensors.\n",
    "\n",
    "To demonstrate their use, we set our objective to arrive at a model representable by the [graph](./ragged.pdf).\n",
    "\n",
    "Just as before, we need to prep our environment to run any meaningful code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import dataset as qd\n",
    "ks = tf.keras\n",
    "kl = ks.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our already created meta data from the sources gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ', ':', '|', 'x', 'y', '=', ',', '+', '-', '*', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n"
     ]
    }
   ],
   "source": [
    "print(qd.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our previously introduced `adapter` to our various datasets, themselves loadable from our stored samples, is adjusted slightly: we don't immediately convert the created ragged tensors to dense tensors anymore.\n",
    "\n",
    "While Keras has the intention of supporting ragged input tensors (the `ragged=True` optional keyword argument is already available), passing in our `composite tensors` doesn't seem to work just yet. To work around this problem, we split our ragged tensors into its components, pass the components in and then reassemble them, once inside the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def adapter(d):\n",
    "    ds = tf.RaggedTensor.from_sparse(d['defs'])\n",
    "    ss = tf.fill([ds.nrows(), 1], qd.SEP)\n",
    "    os = tf.RaggedTensor.from_sparse(d['op'])\n",
    "    x = tf.concat([ds, ss, os], axis=1)\n",
    "    y = tf.RaggedTensor.from_sparse(d['res'])[:, :1].to_tensor()\n",
    "    return (x.flat_values, x.row_splits), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the adapter configured, our dataset streaming function is simple and looks as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dset_for(ps):\n",
    "    ds = tf.data.TFRecordDataset(list(qd.files(ps)))\n",
    "    ds = ds.batch(ps.dim_batch)\n",
    "    fs = {\n",
    "        'defs': tf.io.VarLenFeature(tf.int64),\n",
    "        'op': tf.io.VarLenFeature(tf.int64),\n",
    "        'res': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    ds = ds.map(lambda x: tf.io.parse_example(x, fs)).map(qd.caster)\n",
    "    return ds.map(adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in our previous blog, our elementary math training problem calls for first embedding the passed-in tokens into more spacious hidden dimensions.\n",
    "\n",
    "Hence our already defined `Embed` class only needs to be adjusted to work with ragged tensor arguments. Specifically, after reassembling our `RaggedTensor` inputs from its passed-in components, we simply apply our trusty `embedding_lookup` to all the flattened or \"bunched-up\" tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embed(kl.Layer):\n",
    "    def __init__(self, ps):\n",
    "        super().__init__(dtype=tf.float32)\n",
    "        s = (ps.dim_vocab, ps.dim_hidden)\n",
    "        self.emb = self.add_weight(name='emb', shape=s)\n",
    "\n",
    "    def call(self, x):\n",
    "        fv, rs = x\n",
    "        x = tf.RaggedTensor.from_row_splits(fv, rs)\n",
    "        y = tf.ragged.map_flat_values(tf.nn.embedding_lookup, self.emb, x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `Reflect` layer will need slightly more changes.\n",
    "\n",
    "As the `flat_values` of our ragged inputs loose their batch dimensions, the matrix multiplications become simpler (expressed here through the favorite `einsum`, see [here](https://rockt.github.io/2018/04/30/einsum)).\n",
    "\n",
    "Since the `attention` mechanism's `q`, `k` and `v` components are element-wise tied to their inputs, the new \"raggedness\" of the inputs doesn't change their scope. This means that we only need to change the content of our `RaggedTensor`s, the \"row_lengths\" stay the same as implemented by the `with_values` method.\n",
    "\n",
    "When we switch over to cross-products, for scoring our calculated attention coefficients, we need to use dense tensors once again. But the actual result of the layer is a `RaggedTensor`.\n",
    "\n",
    "Since its \"raggedness\" is the same as the layer's input's raggedness, we can conveniently recreate the same shaped `RaggedTensor` from the respective values of the just calculated dense tensor by using the original ragged input's `row_lengths` method. Very convenient indeed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reflect(kl.Layer):\n",
    "    def build(self, shape):\n",
    "        s = shape[-1]\n",
    "        self.scale = 1 / (s**0.5)\n",
    "        self.q = self.add_weight(name='q', shape=(s, s))\n",
    "        self.k = self.add_weight(name='k', shape=(s, s))\n",
    "        self.v = self.add_weight(name='v', shape=(s, s))\n",
    "        return super().build(shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        q = x.with_values(tf.einsum('ni,ij->nj', x.flat_values, self.q))\n",
    "        k = x.with_values(tf.einsum('ni,ij->nj', x.flat_values, self.k))\n",
    "        v = x.with_values(tf.einsum('ni,ij->nj', x.flat_values, self.v))\n",
    "        y = tf.einsum('bsi,bzi->bsz', q.to_tensor(), k.to_tensor())\n",
    "        y = tf.nn.softmax(y * self.scale)\n",
    "        y = tf.einsum('bsz,bzi->bsi', y, v.to_tensor())\n",
    "        y = tf.RaggedTensor.from_tensor(y, lengths=x.row_lengths())\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to implement similar changes in our `Expand` layer.\n",
    "\n",
    "\"Inflating\" our hidden dimensions, for the intrinsic learning purposes, requires a fixed width, hence we immediately convert to a larger dense tensor. However, as we are done with our \"ragged\" token calculations, we can simply pad the input to the layer to our expected `len_max_input`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expand(kl.Layer):\n",
    "    def __init__(self, ps):\n",
    "        super().__init__()\n",
    "        self.ps = ps\n",
    "\n",
    "    def call(self, x):\n",
    "        y = x.to_tensor()\n",
    "        s = tf.shape(y)[-2]\n",
    "        y = tf.pad(y, [[0, 0], [0, self.ps.len_max_input - s], [0, 0]])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready now to define our model.\n",
    "\n",
    "We have the two inputs, the two components of our input `RaggedTensor`. We also use our new `Embed`, `Reflect` and `Expand` layers adjusted to work with our sudden \"raggedness\". The rest of the model is simply carried over from the previous blog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for(ps):\n",
    "    x = [\n",
    "        ks.Input(shape=(), dtype='int32'),  # , ragged=True)\n",
    "        ks.Input(shape=(), dtype='int64'),\n",
    "    ]\n",
    "    y = Embed(ps)(x)\n",
    "    y = Reflect()(y)\n",
    "    y = Expand(ps)(y)\n",
    "    y = kl.Reshape((ps.len_max_input * ps.dim_hidden, ))(y)\n",
    "    y = kl.Dense(ps.dim_dense, activation='relu')(y)\n",
    "    y = kl.Dense(ps.dim_vocab, name='dbd', activation=None)(y)\n",
    "    m = ks.Model(inputs=x, outputs=y)\n",
    "    m.compile(optimizer=ps.optimizer, loss=ps.loss, metrics=[ps.metric])\n",
    "    print(m.summary())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our parameters are also unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    dim_batch=2,\n",
    "    dim_dense=150,\n",
    "    dim_hidden=15,\n",
    "    dim_vocab=len(qd.vocab),\n",
    "    len_max_input=20,\n",
    "    loss=ks.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metric=ks.metrics.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    num_epochs=10,\n",
    "    num_shards=2,\n",
    "    optimizer=ks.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By firing up our training session, we can confirm the model's layers and connections. Also, the listing of a short session follows.\n",
    "\n",
    "We can easily adjust the parameters to tailor the length of the sessions to our objectives. However, at this point the results are still largely meaningless and extending the trainings is not yet warranted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embed (Embed)                   (None, None, 15)     300         input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reflect (Reflect)               (None, None, 15)     675         embed[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "expand (Expand)                 (None, None, 15)     0           reflect[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 300)          0           expand[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 150)          45150       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dbd (Dense)                     (None, 20)           3020        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 49,145\n",
      "Trainable params: 49,145\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.7148 - sparse_categorical_crossentropy: 1.7148\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.4729 - sparse_categorical_crossentropy: 1.4729\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3973 - sparse_categorical_crossentropy: 1.3973\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3517 - sparse_categorical_crossentropy: 1.3517\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3136 - sparse_categorical_crossentropy: 1.3136\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2838 - sparse_categorical_crossentropy: 1.2838\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2500 - sparse_categorical_crossentropy: 1.2500\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2134 - sparse_categorical_crossentropy: 1.2134\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1745 - sparse_categorical_crossentropy: 1.1745\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1284 - sparse_categorical_crossentropy: 1.1284\n"
     ]
    }
   ],
   "source": [
    "ps = qd.Params(**params)\n",
    "import masking as qm\n",
    "qm.main_graph(ps, dset_for(ps), model_for(ps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our TensorBoard `callback` in place, the model's `fit` method will generate the standard summaries that TB can conveniently visualize.\n",
    "\n",
    "If you haven't run the code, an already generated graph is [here](./ragged.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "#%tensorboard --logdir /tmp/q/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also switch over to the new `eager` execution mode. This is particularly convenient for experimentation, as all ops are immediately executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_eager(ps, ds, m):\n",
    "    def step(x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = m(x)\n",
    "            loss = ps.loss(y, logits)\n",
    "            loss += sum(m.losses)\n",
    "            xent = ps.metric(y, logits)\n",
    "        grads = tape.gradient(loss, m.trainable_variables)\n",
    "        ps.optimizer.apply_gradients(zip(grads, m.trainable_variables))\n",
    "        return loss, xent\n",
    "\n",
    "    @tf.function\n",
    "    def epoch():\n",
    "        s, loss, xent = 0, 0.0, 0.0\n",
    "        for x, y in ds:\n",
    "            s += 1\n",
    "            loss, xent = step(x, y)\n",
    "            if tf.equal(s % 10, 0):\n",
    "                e = ps.metric.result()\n",
    "                tf.print('Step:', s, ', loss:', loss, ', xent:', e)\n",
    "        return loss, xent\n",
    "\n",
    "    for e in range(ps.num_epochs):\n",
    "        loss, xent = epoch()\n",
    "        print(f'Epoch {e} loss:', loss.numpy(), ', xent:', xent.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a much shortened `eager` session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embed_2 (Embed)                 (None, None, 15)     300         input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reflect_2 (Reflect)             (None, None, 15)     675         embed_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "expand_2 (Expand)               (None, None, 15)     0           reflect_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 300)          0           expand_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 150)          45150       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dbd (Dense)                     (None, 20)           3020        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 49,145\n",
      "Trainable params: 49,145\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Step: 10 , loss: 2.32437706 , xent: 1.38269854\n",
      "Step: 20 , loss: 4.57577085 , xent: 1.38721442\n",
      "Step: 30 , loss: 1.85324097 , xent: 1.39087987\n",
      "Step: 40 , loss: 3.42399216 , xent: 1.39260852\n",
      "Step: 50 , loss: 2.88146091 , xent: 1.3952688\n",
      "Step: 60 , loss: 1.36529291 , xent: 1.39925313\n",
      "Step: 70 , loss: 2.36236858 , xent: 1.40269136\n",
      "Step: 80 , loss: 1.86278176 , xent: 1.40463638\n",
      "Step: 90 , loss: 3.87270284 , xent: 1.40630019\n",
      "Step: 100 , loss: 2.69483709 , xent: 1.40788627\n",
      "Epoch 0 loss: 2.694837 , xent: 1.4078863\n"
     ]
    }
   ],
   "source": [
    "ps.num_epochs = 1\n",
    "main_eager(ps, dset_for(ps).take(100), model_for(ps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our blog, please see how to avoid \"layer-proliferation\" complexity by clicking on the next blog."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.qpy)",
   "language": "python",
   "name": "qpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
